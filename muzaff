import csv
import requests
from bs4 import BeautifulSoup
import time
import re
from urllib.parse import urlparse
import logging
from typing import List, Dict, Optional, Tuple
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CompetitorPriceScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        self.results = []
        
    def extract_price_from_html(self, html_content: str, competitor_name: str) -> Optional[str]:
        """
        Extract price from HTML content based on competitor-specific patterns
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Common price patterns
        price_patterns = [
            r'Rs\.?\s*([\d,]+(?:\.\d{2})?)',
            r'PKR\s*([\d,]+(?:\.\d{2})?)',
            r'Price:\s*Rs\.?\s*([\d,]+(?:\.\d{2})?)',
            r'[\d,]+(?:\.\d{2})?\s*Rs',
            r'[\d,]+(?:\.\d{2})?\s*PKR',
            r'Rs\s*([\d,]+(?:\.\d{2})?)',
            r'PKR\s*([\d,]+(?:\.\d{2})?)',
            r'([\d,]+(?:\.\d{2})?)\s*Rs',
            r'([\d,]+(?:\.\d{2})?)\s*PKR',
            # Metro specific patterns
            r'[\d,]+(?:\.\d{2})?',
            r'Price\s*:?\s*([\d,]+(?:\.\d{2})?)',
            r'[\d,]+(?:\.\d{2})?\s*PKR',
            r'PKR\s*([\d,]+(?:\.\d{2})?)'
        ]
        
        # Competitor-specific selectors
        competitor_selectors = {
            'Cartpk': [
                '.price', '.product-price', '.amount', '[class*="price"]',
                '[class*="Price"]', '.current-price', '.regular-price',
                '.product-details-price', '.price-box', '.price-wrapper'
            ],
            'Diamond': [
                '.price', '.product-price', '.amount', '[class*="price"]',
                '[class*="Price"]', '.current-price', '.regular-price',
                '.product-details-price', '.price-box', '.price-wrapper'
            ],
            'Naheed': [
                '.price', '.product-price', '.amount', '[class*="price"]',
                '[class*="Price"]', '.current-price', '.regular-price',
                '.product-details-price', '.price-box', '.price-wrapper'
            ],
            'Metro': [
                '.price', '.product-price', '.amount', '[class*="price"]',
                '[class*="Price"]', '.current-price', '.regular-price',
                '.product-details-price', '.price-box', '.price-wrapper',
                '.product-price-box', '.price-display', '.price-value',
                '.product-price-value', '.price-amount', '.product-amount',
                '[data-price]', '[data-amount]', '.cost', '.value',
                '.product-cost', '.product-value', '.selling-price',
                '.offer-price', '.discount-price', '.final-price'
            ]
        }
        
        # Special handling for Metro
        if competitor_name == 'Metro':
            logger.info(f"Debug: Analyzing Metro page structure")
            
            # First, try to extract price from JSON data in script tags (Metro stores prices here)
            scripts = soup.find_all('script')
            for script in scripts:
                script_text = script.get_text()
                if script_text:
                    # Look for JSON data containing price information
                    if '"price"' in script_text and '"sell_price"' in script_text:
                        logger.info(f"Debug: Found Metro JSON data with prices")
                        # Extract price from JSON
                        price_match = re.search(r'"price":(\d+(?:\.\d+)?)', script_text)
                        sell_price_match = re.search(r'"sell_price":(\d+(?:\.\d+)?)', script_text)
                        
                        if sell_price_match:
                            price = sell_price_match.group(1)
                            logger.info(f"Debug: Found Metro sell_price: {price}")
                            if self.is_valid_price(price):
                                return self.format_price(price)
                        
                        if price_match:
                            price = price_match.group(1)
                            logger.info(f"Debug: Found Metro price: {price}")
                            if self.is_valid_price(price):
                                return self.format_price(price)
            
            # Use the specific Metro price selector path provided by user
            price_selector = "#__next > div > div.main-container > div > div.CategoryGrid_product_details_container_without_imageCarousel__xOYB6 > div.CategoryGrid_product_details_description_container__OjSn3 > p.CategoryGrid_product_details_price__dNQQQ"
            price_tag = soup.select_one(price_selector)
            
            if price_tag:
                price_text = price_tag.get_text(strip=True)
                logger.info(f"Debug: Found Metro price using specific selector: '{price_text}'")
                price = self.extract_price_from_text(price_text)
                if price and self.is_valid_price(price):
                    logger.info(f"Debug: Found Metro price: {price}")
                    return self.format_price(price)
            
            # Also try the shorter class name as fallback
            price_tag = soup.find("p", class_="CategoryGrid_product_details_price__dNQQQ")
            if price_tag:
                price_text = price_tag.get_text(strip=True)
                logger.info(f"Debug: Found Metro price using class selector: '{price_text}'")
                price = self.extract_price_from_text(price_text)
                if price and self.is_valid_price(price):
                    logger.info(f"Debug: Found Metro price: {price}")
                    return self.format_price(price)
            
            # Fallback to other Metro selectors if the specific class is not found
            metro_price_selectors = [
                # Primary Metro selectors - focus on product areas
                '.product-price', '.price-display', '.price-value',
                '.product-price-value', '.price-amount', '.product-amount',
                '.selling-price', '.offer-price', '.discount-price', '.final-price',
                '.price-box', '.price-container', '.product-price-box',
                '.price-wrapper', '.price-section', '.product-price-section',
                # More specific Metro selectors
                '.product-details-price', '.current-price', '.regular-price',
                '.product-price-display', '.price-text', '.price-label',
                # Generic price selectors
                '.price', '.amount', '.product-price',
                '[class*="price"]', '[class*="Price"]', '[class*="amount"]',
                '[class*="Amount"]', '[class*="cost"]', '[class*="Cost"]',
                # Data attributes
                '[data-price]', '[data-amount]', '[data-value]',
                # Additional Metro specific patterns
                '.cost', '.value', '.product-cost', '.product-value',
                # Metro specific product containers
                '.product-details', '.product-info', '.product-summary',
                '.product-description', '.product-content'
            ]
            
            # First try to find price in specific Metro elements
            for selector in metro_price_selectors:
                elements = soup.select(selector)
                for element in elements:
                    text = element.get_text(strip=True)
                    # Skip very short or very long text
                    if len(text) < 3 or len(text) > 100:
                        continue
                    
                    # Check for data attributes first
                    if element.has_attr('data-price'):
                        price = str(element['data-price'])
                        if self.is_valid_price(price):
                            logger.info(f"Debug: Found Metro price in data-price: {price}")
                            return self.format_price(price)
                    
                    if element.has_attr('data-amount'):
                        price = str(element['data-amount'])
                        if self.is_valid_price(price):
                            logger.info(f"Debug: Found Metro price in data-amount: {price}")
                            return self.format_price(price)
                    
                    logger.info(f"Debug: Metro selector '{selector}' found text: '{text}'")
                    price = self.extract_price_from_text(text)
                    if price and self.is_valid_price(price):
                        logger.info(f"Debug: Found Metro price in selector '{selector}': {price}")
                        return price
            
            # If no price found in specific selectors, try broader search with better filtering
            logger.info("Debug: No price found in specific selectors, trying broader search")
            
            # Focus on main content area, avoid header/footer
            main_content_selectors = [
                'main', '.main-content', '.content', '.product-content',
                '.product-details', '.product-info', '.product-summary',
                '.product-description', '.product-container'
            ]
            
            search_elements = []
            for selector in main_content_selectors:
                elements = soup.select(selector)
                if elements:
                    search_elements.extend(elements)
            
            # If no main content found, search all elements but exclude header/footer
            if not search_elements:
                # Exclude header, footer, navigation areas
                for element in soup.find_all(['header', 'footer', 'nav']):
                    element.decompose()
                search_elements = soup.find_all(['span', 'div', 'p', 'strong', 'b', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
            else:
                # Search within main content elements
                for main_element in search_elements:
                    search_elements.extend(main_element.find_all(['span', 'div', 'p', 'strong', 'b', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']))
            
            potential_prices = []
            
            for element in search_elements:
                text = element.get_text(strip=True)
                if len(text) > 5 and len(text) < 100:  # Reasonable text length
                    # Look for price patterns in this element
                    if re.search(r'Rs\.?\s*\d+', text) or re.search(r'PKR\s*\d+', text) or re.search(r'\d+\s*Rs', text):
                        logger.info(f"Debug: Found potential price element: '{text}'")
                        price = self.extract_price_from_text(text)
                        if price and self.is_valid_price(price):
                            potential_prices.append((price, text))
            
            # Sort potential prices by value and return the highest reasonable one
            if potential_prices:
                potential_prices.sort(key=lambda x: float(x[0]), reverse=True)
                for price, text in potential_prices:
                    if self.is_valid_price(price):
                        logger.info(f"Debug: Selected Metro price: {price} from text: '{text}'")
                        return price
            
            # If we still haven't found a price, the product might not be available
            logger.warning(f"Debug: No valid Metro price found - product may be unavailable")
            return None
        
        # Try competitor-specific selectors first
        if competitor_name in competitor_selectors:
            for selector in competitor_selectors[competitor_name]:
                price_elements = soup.select(selector)
                for element in price_elements:
                    text = element.get_text(strip=True)
                    price = self.extract_price_from_text(text)
                    if price:
                        return price
        
        # Fallback: search entire text for price patterns
        text = soup.get_text()
        return self.extract_price_from_text(text)
    
    def extract_price_from_text(self, text: str) -> Optional[str]:
        """
        Extract price from text using various patterns
        """
        price_patterns = [
            r'Rs\.?\s*([\d,]+(?:\.\d{2})?)',
            r'PKR\s*([\d,]+(?:\.\d{2})?)',
            r'Price:\s*Rs\.?\s*([\d,]+(?:\.\d{2})?)',
            r'[\d,]+(?:\.\d{2})?\s*Rs',
            r'[\d,]+(?:\.\d{2})?\s*PKR',
            r'Rs\s*([\d,]+(?:\.\d{2})?)',
            r'PKR\s*([\d,]+(?:\.\d{2})?)',
            r'([\d,]+(?:\.\d{2})?)\s*Rs',
            r'([\d,]+(?:\.\d{2})?)\s*PKR',
            r'Price\s*:?\s*([\d,]+(?:\.\d{2})?)',
            r'([\d,]+(?:\.\d{2})?)'
        ]
        
        for pattern in price_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0]
                    if self.is_valid_price(match):
                        return self.format_price(match)
        
        return None
    
    def is_valid_price(self, price_str: str) -> bool:
        """
        Check if a string represents a valid price
        """
        try:
            # Remove commas and extract only digits and decimal
            clean_price = re.sub(r'[^\d.]', '', str(price_str))
            if clean_price and float(clean_price) > 0:  # Any positive price is valid
                return True
        except (ValueError, TypeError):
            pass
        return False
    
    def format_price(self, price_str: str) -> str:
        """
        Format price to 2 decimal places
        """
        try:
            # Remove commas and extract only digits and decimal
            clean_price = re.sub(r'[^\d.]', '', str(price_str))
            if clean_price:
                formatted_price = f"{float(clean_price):.2f}"
                return formatted_price
        except (ValueError, TypeError):
            pass
        return price_str
    
    def scrape_price(self, url: str, competitor_name: str) -> Optional[str]:
        """
        Scrape price from a given URL with retry logic
        """
        max_retries = 3
        base_delay = 10  # Increased base delay
        
        for attempt in range(max_retries):
            try:
                logger.info(f"Scraping price from {competitor_name}: {url} (Attempt {attempt + 1}/{max_retries})")
                
                # Add longer delay to avoid detection
                if attempt > 0:
                    delay = base_delay * (attempt + 1)  # 20s, 30s delays
                    logger.info(f"Waiting {delay} seconds before retry...")
                    time.sleep(delay)
                
                # For Metro, use Selenium directly
                if competitor_name == 'Metro':
                    price = self.get_metro_price_selenium(url)
                else:
                    # For other competitors, use requests/BeautifulSoup
                    response = self.session.get(url, timeout=45)  # Increased timeout
                    response.raise_for_status()
                    soup = BeautifulSoup(response.text, 'html.parser')
                    price = self.get_competitor_price(competitor_name, url, soup)
                
                if price:
                    logger.info(f"Found price for {competitor_name}: Rs. {price}")
                else:
                    logger.warning(f"No price found for {competitor_name}: {url}")
                
                return price
                
            except (requests.ConnectionError, requests.Timeout, requests.RequestException) as e:
                # Handle 404 errors immediately - skip to next product
                if "404" in str(e) or "Not Found" in str(e):
                    logger.warning(f"404 error for {competitor_name}: {url} - Skipping to next product")
                    return None
                
                logger.error(f"Connection error scraping {competitor_name}: {url} - {str(e)} (Attempt {attempt + 1}/{max_retries})")
                if attempt == max_retries - 1:
                    logger.error(f"Failed to scrape {competitor_name} after {max_retries} attempts")
                    return None
                continue
            except Exception as e:
                logger.error(f"Unexpected error scraping {competitor_name}: {url} - {str(e)} (Attempt {attempt + 1}/{max_retries})")
                if attempt == max_retries - 1:
                    return None
                continue
        
        return None
    
    def get_competitor_name_from_url(self, url: str) -> str:
        """
        Extract competitor name from URL
        """
        # Handle URLs without protocol
        if url.startswith('www.'):
            url = 'https://' + url
        
        domain = urlparse(url).netloc.lower()
        
        if 'cartpk.com' in domain:
            return 'Cartpk'
        elif 'dsmonline.pk' in domain:
            return 'Diamond'
        elif 'naheed.pk' in domain:
            return 'Naheed'
        elif 'metro-online.pk' in domain:
            return 'Metro'
        else:
            return 'Unknown'
    
    def process_csv(self, csv_file_path: str):
        """
        Process the CSV file and scrape prices from all competitors one by one
        """
        logger.info("Starting to process CSV file...")
        
        try:
            with open(csv_file_path, 'r', encoding='utf-8') as file:
                reader = csv.reader(file)
                rows = list(reader)
                
                if len(rows) < 3:
                    logger.error("CSV file doesn't have enough rows")
                    return
                
                # Extract competitor URLs from header
                competitor_urls = rows[0][1:]  # Skip first empty column
                competitor_names = [self.get_competitor_name_from_url(url) for url in competitor_urls]
                
                logger.info(f"Found competitors: {competitor_names}")
                
                # Process each competitor separately
                for comp_idx, (comp_url, comp_name) in enumerate(zip(competitor_urls, competitor_names)):
                    logger.info(f"\n{'='*50}")
                    logger.info(f"Processing competitor: {comp_name}")
                    logger.info(f"{'='*50}")
                    
                    # Reset results for this competitor
                    self.results = []
                    
                    # Process each product row for this competitor
                    for row_idx, row in enumerate(rows[2:], start=3):  # Start from row 3 (after headers)
                        if len(row) < 2:
                            continue
                        
                        sku = row[0]
                        product_link = row[comp_idx + 1]  # Get link for this specific competitor
                        
                        if not product_link or product_link.strip() == '':
                            logger.info(f"Skipping empty link for {comp_name} - SKU: {sku}")
                            continue
                        
                        logger.info(f"Processing SKU: {sku}")
                        
                        # Add delay between requests to be respectful
                        if row_idx > 3:  # Not the first request
                            time.sleep(5)  # Increased from 2 to 5 seconds
                        
                        price = self.scrape_price(product_link.strip(), comp_name)
                        
                        if price:
                            self.results.append({
                                'SKU': sku,
                                'Competitor_Price': price,
                                'Competitor_Name': comp_name,
                                'Competitor_Link': product_link.strip()
                            })
                    
                    # Save results for this competitor
                    self.save_competitor_results(comp_name)
                    if self.results:
                        logger.info(f"Completed {comp_name}: {len(self.results)} products found")
                    else:
                        logger.warning(f"No results found for {comp_name}")
                    
                    # Add delay between competitors
                    if comp_idx < len(competitor_names) - 1:
                        logger.info("Waiting 5 seconds before processing next competitor...")
                        time.sleep(5)
                
                logger.info(f"\nCompleted processing all competitors.")
                
        except FileNotFoundError:
            logger.error(f"CSV file not found: {csv_file_path}")
        except Exception as e:
            logger.error(f"Error processing CSV file: {str(e)}")
    
    def save_competitor_results(self, competitor_name: str):
        """
        Save results for a specific competitor to a separate CSV file
        """
        # Create filename based on competitor name
        filename = f"{competitor_name.lower()}_prices.csv"
        
        try:
            with open(filename, 'w', newline='', encoding='utf-8') as file:
                fieldnames = ['SKU', 'Competitor_Price', 'Competitor_Name', 'Competitor_Link']
                writer = csv.DictWriter(file, fieldnames=fieldnames)
                
                writer.writeheader()
                
                if self.results:
                    for result in self.results:
                        writer.writerow(result)
                    logger.info(f"Results saved to {filename}")
                    logger.info(f"Total entries for {competitor_name}: {len(self.results)}")
                else:
                    # Add a row indicating no prices were found
                    writer.writerow({
                        'SKU': 'No products available',
                        'Competitor_Price': 'N/A',
                        'Competitor_Name': competitor_name,
                        'Competitor_Link': 'N/A'
                    })
                    logger.info(f"Empty results file created: {filename}")
                    logger.info(f"No prices found for {competitor_name} - products may be unavailable")
            
        except Exception as e:
            logger.error(f"Error saving results for {competitor_name}: {str(e)}")
    
    def save_results(self, output_file: str = 'competitor_prices.csv'):
        """
        This method is kept for backward compatibility but is no longer used
        """
        logger.warning("This method is deprecated. Use save_competitor_results() instead.")
        pass

    def get_metro_price_selenium(self, url):
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--window-size=1920,1080')
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        try:
            driver.get(url)
            wait = WebDriverWait(driver, 20)
            # Try the specific product detail price selector first
            try:
                price_elem = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'p.CategoryGrid_product_details_price__dNQQQ')))
                price_text = price_elem.text.strip()
                price = self.extract_price_from_text(price_text)
                if price and self.is_valid_price(price):
                    return self.format_price(price)
            except Exception:
                # Fallback: try all p.CategoryGrid_product_price__Svf8T elements and pick the lowest
                price_elements = driver.find_elements(By.CSS_SELECTOR, 'p.CategoryGrid_product_price__Svf8T')
                prices = []
                for elem in price_elements:
                    text = elem.text.strip()
                    price = self.extract_price_from_text(text)
                    if price and self.is_valid_price(price):
                        prices.append(float(price))
                if prices:
                    min_price = min(prices)
                    return f"{min_price:.2f}"
            return None
        except Exception as e:
            print(f"Selenium Metro error: {e}")
            return None
        finally:
            driver.quit()

    def get_competitor_price(self, competitor_name, url, soup=None):
        if competitor_name == 'Metro':
            return self.get_metro_price_selenium(url)
        
        # For other competitors, use the existing BeautifulSoup logic
        if soup is None:
            return None
            
        # Try competitor-specific selectors first
        competitor_selectors = {
            'Cartpk': [
                '.price', '.product-price', '.price-display', '.price-value',
                '.product-price-value', '.price-amount', '.product-amount',
                '.selling-price', '.offer-price', '.discount-price', '.final-price',
                '.price-box', '.price-container', '.product-price-box',
                '.price-wrapper', '.price-section', '.product-price-section',
                '.product-details-price', '.current-price', '.regular-price',
                '.product-price-display', '.price-text', '.price-label',
                '[class*="price"]', '[class*="Price"]', '[class*="amount"]',
                '[class*="Amount"]', '[class*="cost"]', '[class*="Cost"]',
                '[data-price]', '[data-amount]', '[data-value]',
                '.cost', '.value', '.product-cost', '.product-value',
                '.product-details', '.product-info', '.product-summary',
                '.product-description', '.product-content'
            ],
            'Diamond': [
                '.price', '.product-price', '.price-display', '.price-value',
                '.product-price-value', '.price-amount', '.product-amount',
                '.selling-price', '.offer-price', '.discount-price', '.final-price',
                '.price-box', '.price-container', '.product-price-box',
                '.price-wrapper', '.price-section', '.product-price-section',
                '.product-details-price', '.current-price', '.regular-price',
                '.product-price-display', '.price-text', '.price-label',
                '[class*="price"]', '[class*="Price"]', '[class*="amount"]',
                '[class*="Amount"]', '[class*="cost"]', '[class*="Cost"]',
                '[data-price]', '[data-amount]', '[data-value]',
                '.cost', '.value', '.product-cost', '.product-value',
                '.product-details', '.product-info', '.product-summary',
                '.product-description', '.product-content'
            ],
            'Naheed': [
                '.price', '.product-price', '.price-display', '.price-value',
                '.product-price-value', '.price-amount', '.product-amount',
                '.selling-price', '.offer-price', '.discount-price', '.final-price',
                '.price-box', '.price-container', '.product-price-box',
                '.price-wrapper', '.price-section', '.product-price-section',
                '.product-details-price', '.current-price', '.regular-price',
                '.product-price-display', '.price-text', '.price-label',
                '[class*="price"]', '[class*="Price"]', '[class*="amount"]',
                '[class*="Amount"]', '[class*="cost"]', '[class*="Cost"]',
                '[data-price]', '[data-amount]', '[data-value]',
                '.cost', '.value', '.product-cost', '.product-value',
                '.product-details', '.product-info', '.product-summary',
                '.product-description', '.product-content'
            ]
        }
        
        if competitor_name in competitor_selectors:
            for selector in competitor_selectors[competitor_name]:
                price_elements = soup.select(selector)
                for element in price_elements:
                    text = element.get_text(strip=True)
                    price = self.extract_price_from_text(text)
                    if price:
                        return price
        
        # Fallback: search entire text for price patterns
        text = soup.get_text()
        return self.extract_price_from_text(text)

def main():
    """
    Main function to run the price scraping process
    """
    print("Competitor Price Scraper")
    print("="*40)
    
    # Initialize scraper
    scraper = CompetitorPriceScraper()
    
    # Process the CSV file
    csv_file = "Cartpk competitors link(Developer Sample File).csv"
    scraper.process_csv(csv_file)
    
    print("\nProcess completed!")
    print("Check the generated CSV files for each competitor.")

if __name__ == "__main__":
    main()
